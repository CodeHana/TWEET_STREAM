{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1ff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb1dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from MySQL to perform exploratory data analysis\n",
    "import settings\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import time\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "py.init_notebook_mode()\n",
    "    \n",
    "import re\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Filter constants for states in US\n",
    "STATES = ['Alabama', 'AL', 'Alaska', 'AK', 'American Samoa', 'AS', 'Arizona', 'AZ', 'Arkansas', 'AR', 'California', 'CA', 'Colorado', 'CO', 'Connecticut', 'CT', 'Delaware', 'DE', 'District of Columbia', 'DC', 'Federated States of Micronesia', 'FM', 'Florida', 'FL', 'Georgia', 'GA', 'Guam', 'GU', 'Hawaii', 'HI', 'Idaho', 'ID', 'Illinois', 'IL', 'Indiana', 'IN', 'Iowa', 'IA', 'Kansas', 'KS', 'Kentucky', 'KY', 'Louisiana', 'LA', 'Maine', 'ME', 'Marshall Islands', 'MH', 'Maryland', 'MD', 'Massachusetts', 'MA', 'Michigan', 'MI', 'Minnesota', 'MN', 'Mississippi', 'MS', 'Missouri', 'MO', 'Montana', 'MT', 'Nebraska', 'NE', 'Nevada', 'NV', 'New Hampshire', 'NH', 'New Jersey', 'NJ', 'New Mexico', 'NM', 'New York', 'NY', 'North Carolina', 'NC', 'North Dakota', 'ND', 'Northern Mariana Islands', 'MP', 'Ohio', 'OH', 'Oklahoma', 'OK', 'Oregon', 'OR', 'Palau', 'PW', 'Pennsylvania', 'PA', 'Puerto Rico', 'PR', 'Rhode Island', 'RI', 'South Carolina', 'SC', 'South Dakota', 'SD', 'Tennessee', 'TN', 'Texas', 'TX', 'Utah', 'UT', 'Vermont', 'VT', 'Virgin Islands', 'VI', 'Virginia', 'VA', 'Washington', 'WA', 'West Virginia', 'WV', 'Wisconsin', 'WI', 'Wyoming', 'WY']\n",
    "STATE_DICT = dict(itertools.zip_longest(*[iter(STATES)] * 2, fillvalue=\"\"))\n",
    "INV_STATE_DICT = dict((v,k) for k,v in STATE_DICT.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de740b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to DB\n",
    "def connect_db(): \n",
    "    db_connection = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        passwd=\"11223344\",\n",
    "        database=\"tweetdb\",\n",
    "        charset = 'utf8'\n",
    "     )\n",
    "    return db_connection\n",
    "\n",
    "def query_db(st_time):\n",
    "    db_connection = connect_db()\n",
    "    # query tweet data every 30 mins\n",
    "    query = \"SELECT * FROM {} WHERE created_at >= '{}'\".format(settings.TABLE_NAME, st_time)\n",
    "    df = pd.read_sql(query, con=db_connection)\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41f52d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7cfb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "\n",
    "    clear_output()\n",
    "\n",
    "        # set data collect/display time interval - every 30 mins\n",
    "    st_time_before_30mins = (datetime.datetime.utcnow() - datetime.timedelta(hours=0, minutes=30)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    st_time_before_day = (datetime.datetime.utcnow() - datetime.timedelta(days=1)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "    df_30mins = query_db(st_time_before_30mins)\n",
    "    df_day = query_db(st_time_before_day)\n",
    "\n",
    "    # run vader sentiment analysis\n",
    "\n",
    "    df_30mins['vader_compound'] = df_30mins['text'].apply(lambda text: vader_sid.polarity_scores(text)['compound'])\n",
    "    df_30mins['vader_polarity'] = df_30mins['vader_compound'].apply(lambda score: 'positive' if score >=0.01 else ('negative' if score <= -0.01 else 'neutral'))\n",
    "\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "    #         column_widths=[1, 0.4],\n",
    "    #         row_heights=[0.6, 0.4],\n",
    "        specs=[[{\"type\": \"scatter\", \"rowspan\": 2}, {\"type\": \"choropleth\"}], [  None  , {\"type\": \"bar\"}]]\n",
    "        )\n",
    "\n",
    "    result_vader_polarity = df_30mins.groupby( [pd.Grouper(key='created_at', freq='10s'), 'vader_polarity']).count().unstack(fill_value=0).stack().reset_index()\n",
    "    result_vader_polarity = result_vader_polarity.rename(columns= { \"id_str\": \"Num of Tweets about '{}'\".format(settings.TRACK_WORDS), \"created_at\":\"Time in UTC\" })\n",
    "\n",
    "    result_vader_score =  df_30mins.groupby( [pd.Grouper(key='created_at', freq='10s'), 'vader_polarity']).mean().unstack(fill_value=0).stack().reset_index()\n",
    "    result_vader_score = result_vader_score.rename(columns= { \"created_at\":\"Time in UTC\" })\n",
    "\n",
    "    result_vader = pd.merge(result_vader_polarity, result_vader_score , on=[\"Time in UTC\", \"vader_polarity\"] )\n",
    "    columns = [\"Time in UTC\", \"vader_polarity\", \"vader_compound_y\", \"Num of Tweets about '{}'\".format(settings.TRACK_WORDS)]\n",
    "  #  result_vader = result_vader[columns]\n",
    "\n",
    "    '''\n",
    "    Plot the Line Chart\n",
    "    '''\n",
    "    time_series = result_vader[\"Time in UTC\"].reset_index(drop=True)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=time_series,\n",
    "        y=result_vader[\"Num of Tweets about '{}'\".format(settings.TRACK_WORDS)][result_vader['vader_polarity']=='neutral'].reset_index(drop=True),name=\"neutral\"), row=1, col=1)   \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=time_series,\n",
    "        y=result_vader[\"Num of Tweets about '{}'\".format(settings.TRACK_WORDS)][result_vader['vader_polarity']=='negative'].reset_index(drop=True),name=\"negative\"), row=1, col=1) \n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=time_series,\n",
    "        y=result_vader[\"Num of Tweets about '{}'\".format(settings.TRACK_WORDS)][result_vader['vader_polarity']=='positive'].reset_index(drop=True),\n",
    "        name=\"positive\"), row=1, col=1) \n",
    "\n",
    "\n",
    "    '''\n",
    "    Plot the Bar Chart\n",
    "    '''\n",
    "    content = ' '.join(df_30mins[\"text\"])\n",
    "    content = re.sub(r\"http\\S+\", \"\", content)\n",
    "    content = content.replace('RT ', ' ').replace('&amp;', 'and')\n",
    "    content = re.sub('[^A-Za-z0-9]+', ' ', content)\n",
    "    content = content.lower()\n",
    "\n",
    "    tokenized_word = word_tokenize(content)\n",
    "    stop_words=set(stopwords.words(\"english\")).union('today', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'time', 'get')\n",
    "    filtered_sent=[]\n",
    "    for w in tokenized_word:\n",
    "        if w not in stop_words:\n",
    "            filtered_sent.append(w)\n",
    "    fdist = FreqDist(filtered_sent)\n",
    "    fd = pd.DataFrame(fdist.most_common(10), columns = [\"Word\",\"Frequency\"]).drop([0]).reindex().sort_values(by = ['Frequency'])\n",
    "    fig.add_trace(go.Bar(x=fd[\"Frequency\"], y=fd[\"Word\"], orientation='h'), row=2, col=2)\n",
    "\n",
    "    '''\n",
    "    Plot the Geo-Distribution\n",
    "    '''\n",
    "\n",
    "    is_in_US=[]\n",
    "    geo = df_day[['user_location']]\n",
    "    df_day = df_day.fillna(\" \")\n",
    "    for x in df_day['user_location']:\n",
    "        check = False\n",
    "        for s in STATES:\n",
    "            if s in x:\n",
    "                is_in_US.append(STATE_DICT[s] if s in STATE_DICT else s)\n",
    "                check = True\n",
    "                break\n",
    "        if not check:\n",
    "            is_in_US.append(None)\n",
    "\n",
    "    geo_dist = pd.DataFrame(is_in_US, columns=['State']).dropna().reset_index()\n",
    "    geo_dist = geo_dist.groupby('State').count().rename(columns={\"index\": \"Number\"}) \\\n",
    "            .sort_values(by=['Number'], ascending=False).reset_index()\n",
    "    #geo_dist[\"Log Num\"] = geo_dist[\"Number\"].apply(lambda x: math.log(x, 2))\n",
    "\n",
    "\n",
    "    geo_dist['Full State Name'] = geo_dist['State'].apply(lambda x: INV_STATE_DICT[x])\n",
    "    geo_dist['text'] = geo_dist['Full State Name'] + '<br>' + 'Num: ' + geo_dist['Number'].astype(str)\n",
    "    fig.add_trace(go.Choropleth(\n",
    "        locations=geo_dist['State'], # Spatial coordinates\n",
    "        z = geo_dist['Number'].astype(float), # Data to be color-coded\n",
    "        locationmode = 'USA-states', # set of locations match entries in `locations`\n",
    "        colorscale = \"Blues\",\n",
    "        text=geo_dist['text'], # hover text\n",
    "        marker_line_color='white', # line markers between states\n",
    "        showscale=False,\n",
    "        geo = 'geo'\n",
    "        ),\n",
    "        row=1, col=2)\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text= \"Real-time tracking '{}' mentions on Twitter {} UTC\".format(settings.TRACK_WORDS[0] ,datetime.datetime.utcnow().strftime('%m-%d %H:%M')),\n",
    "        geo = dict( scope='usa',),\n",
    "        margin=dict(r=20, t=50, b=50, l=20),\n",
    "        annotations=[\n",
    "            go.layout.Annotation(\n",
    "                text=\"Source: Twitter\",\n",
    "                showarrow=True,\n",
    "                xref=\"paper\",\n",
    "                yref=\"paper\",\n",
    "                x=0,\n",
    "                y=0)\n",
    "        ],\n",
    "        showlegend=False,\n",
    "        xaxis_rangeslider_visible=True\n",
    "    )\n",
    "\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "    time.sleep(120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2814356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = connect_db()\n",
    "st_time_before_30mins = (datetime.datetime.utcnow() - datetime.timedelta(hours=0, minutes=30)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "st_time_before_day = (datetime.datetime.utcnow() - datetime.timedelta(days=1)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "# query tweet data every 30 mins\n",
    "query_30mins = \"SELECT * FROM {} WHERE created_at >= '{}'\".format(settings.TABLE_NAME, st_time_before_30mins)\n",
    "df_30mins = pd.read_sql(query_30mins, con=db_connection)\n",
    "df_30mins['created_at'] = pd.to_datetime(df_30mins['created_at'])\n",
    "\n",
    "# query tweet data from a day ahead\n",
    "query_day = \"SELECT * FROM {} WHERE created_at >= '{}'\".format(settings.TABLE_NAME, st_time_before_day)\n",
    "df_day = pd.read_sql(query_day, con=db_connection)\n",
    "df_day['created_at'] = pd.to_datetime(df_day['created_at'])\n",
    "\n",
    "\n",
    "# run vader sentiment analysis\n",
    "vader_sid = SentimentIntensityAnalyzer()\n",
    "df_30mins['vader_compound'] = df_30mins['text'].apply(lambda text: vader_sid.polarity_scores(text)['compound'])\n",
    "df_30mins['vader_polarity'] = df_30mins['vader_compound'].apply(lambda score: 'positive' if score >=0.01 else ('negative' if score <= -0.01 else 'neutral'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de105071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# Clean and transform data to enable time series\n",
    "# Display the line chart for \n",
    "# 1. vader polarity\n",
    "result_vader_polarity = df_30mins.groupby( [pd.Grouper(key='created_at', freq='20s'), 'vader_polarity']).count().unstack(fill_value=0).stack().reset_index()\n",
    "result_vader_polarity = result_vader_polarity.rename(columns= { \"id_str\": \"Num of Tweets about '{}'\".format(settings.TRACK_WORDS), \"created_at\":\"Time in UTC\" })\n",
    "\n",
    "result_vader_score =  df_30mins.groupby( [pd.Grouper(key='created_at', freq='20s'), 'vader_polarity']).mean().unstack(fill_value=0).stack().reset_index()\n",
    "result_vader_score = result_vader_score.rename(columns= { \"created_at\":\"Time in UTC\" })\n",
    "\n",
    "result_vader = pd.merge(result_vader_polarity, result_vader_score , on=[\"Time in UTC\", \"vader_polarity\"] )\n",
    "columns = [\"Time in UTC\", \"vader_polarity\", \"vader_compound_y\", \"Num of Tweets about '{}'\".format(settings.TRACK_WORDS)]\n",
    "result_vader = result_vader[columns]\n",
    "result_vader\n",
    "\n",
    "fig = px.line(result_vader_polarity, x='Time in UTC', y=\"Num of Tweets about '{}'\".format(settings.TRACK_WORDS),  color='vader_polarity')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f546dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.line(result_vader, x=\"Time in UTC\", y='vader_compound_y', title='Tweet',  color='vader_polarity')\n",
    "# fig.update_yaxes(title_text='Number of Tweets')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e32600",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_vader.head(5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d1924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting the overall sensitivity score\n",
    "vader_score =  result_vader_score.groupby( [pd.Grouper(key='Time in UTC', freq='20s')]).mean().reset_index()\n",
    "vader_score = vader_score.rename(columns= {  \"polarity\":\"bolb_score\", \"vader_compound\": \"vader_score\"})\n",
    "time_series = vader_score[\"Time in UTC\"].reset_index(drop=True)\n",
    "fig = px.line(vader_score, x=vader_score['Time in UTC'], y=['vader_score'])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a227b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top words\n",
    "content = ' '.join(df_30mins[\"text\"])\n",
    "content = re.sub(r\"http\\S+\", \"\", content)\n",
    "content = content.replace('RT ', ' ').replace('&amp;', 'and')\n",
    "content = re.sub('[^A-Za-z0-9]+', ' ', content)\n",
    "content = content.lower()\n",
    "\n",
    "tokenized_word = word_tokenize(content)\n",
    "stop_words=set(stopwords.words(\"english\")).union('today', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'time', 'get')\n",
    "filtered_sent=[]\n",
    "for w in tokenized_word:\n",
    "    if w not in stop_words:\n",
    "        filtered_sent.append(w)\n",
    "freq_words = FreqDist(filtered_sent)\n",
    "fd = pd.DataFrame(freq_words.most_common(15), columns = [\"Word\",\"Frequency\"]).drop([0]).reindex().sort_values(by=['Frequency'])\n",
    "\n",
    "fig = px.bar(fd, y=\"Word\", x=\"Frequency\", orientation='h', title='Top Tweet Words:{} '.format(settings.TRACK_WORDS[0]))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e0a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "is_in_US=[]\n",
    "geo = df_day[['user_location']]\n",
    "df_day = df_day.fillna(\" \")\n",
    "for x in df_day['user_location']:\n",
    "    check = False\n",
    "    for s in STATES:\n",
    "        if s in x:\n",
    "            is_in_US.append(STATE_DICT[s] if s in STATE_DICT else s)\n",
    "            check = True\n",
    "            break\n",
    "    if not check:\n",
    "        is_in_US.append(None)\n",
    "\n",
    "geo_dist = pd.DataFrame(is_in_US, columns=['State']).dropna().reset_index()\n",
    "geo_dist = geo_dist.groupby('State').count().rename(columns={\"index\": \"Number\"}).sort_values(by=['Number'], ascending=False).reset_index()\n",
    "\n",
    "geo_dist['FullStateName'] = geo_dist['State'].apply(lambda x: INV_STATE_DICT[x])\n",
    "geo_dist['text'] = geo_dist['FullStateName'] + '<br>' + 'Num: ' + geo_dist['Number'].astype(str)\n",
    "fig.add_trace(go.Choropleth(\n",
    "    locations=geo_dist['State'], # Spatial coordinates\n",
    "    z = geo_dist['Number'].astype(float), # Data to be color-coded\n",
    "    locationmode = 'USA-states', # set of locations match entries in `locations`\n",
    "    colorscale = \"Blues\",\n",
    "    text=geo_dist['text'], # hover text\n",
    "    showscale=False,\n",
    "    geo = 'geo'\n",
    "    ))\n",
    "\n",
    "\n",
    "fig = go.Figure(data=go.Choropleth(\n",
    "    locations=geo_dist['State'], # Spatial coordinates\n",
    "    z = geo_dist['Number'].astype(float), # Data to be color-coded\n",
    "\n",
    "    locationmode = 'USA-states', \n",
    "    colorscale = \"Blues\",\n",
    "    text=geo_dist['text'],\n",
    "    marker_line_color='white', # line markers between states\n",
    "    colorbar_title = \"Numbers of Tweets\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    geo_scope='usa', \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7279943f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd092b2d4e8b25642bb78c007d7a6f40d2ec1a44635e9e21bb5f68c2c2936c06aab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
